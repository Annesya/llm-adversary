# llm-adversary
Generating adversarial attacks for different LLMs (follow-up of Zou et al. 2023)

For experiments 2.1-2.3, see the branch `dev_attack` 
For experiment 2.4, see the branch `dev_dropout`



